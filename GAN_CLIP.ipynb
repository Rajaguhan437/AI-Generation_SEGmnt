{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajaguhan437/Custom_GAN_to_CLIP/blob/main/GAN_CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ4zgF9wO0Lh",
        "outputId": "6adcf53b-ee4f-4051-fbc8-6fd289c79e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (243/243), 8.92 MiB | 8.10 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpsrV51pO0Lj",
        "outputId": "87b8e2fb-685b-4264-9a3f-82b57712fd7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1339, done.\u001b[K\n",
            "remote: Total 1339 (delta 0), reused 0 (delta 0), pack-reused 1339\u001b[K\n",
            "Receiving objects: 100% (1339/1339), 409.77 MiB | 17.69 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "gkK-j2hKPyhR",
        "outputId": "46bbc24e-fe3e-4c3f-93fc-b9e8579f1bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Downloading Libraries and dependenices\n",
        "\n",
        "!pip install --no-deps ftfy regex tqdm\n",
        "!pip install omegaconf==2.0.0 pytorch-lightning==1.0.0\n",
        "!pip install einops\n",
        "\n",
        "# omegaconf ==> to load config files"
      ],
      "metadata": {
        "id": "vfXYBwozP021",
        "outputId": "b6997867-10ae-4b10-94fd-02579ec71d09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: omegaconf==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Collecting pytorch-lightning==1.0.0\n",
            "  Using cached pytorch_lightning-1.0.0-py3-none-any.whl (510 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.0.0) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.0.0) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (0.18.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (2023.4.0)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.0.0) (2.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.54.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.0.0) (0.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-lightning==1.0.0) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-lightning==1.0.0) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-lightning==1.0.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-lightning==1.0.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-lightning==1.0.0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch-lightning==1.0.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.3->pytorch-lightning==1.0.0) (16.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-lightning==1.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.0.0) (3.2.2)\n",
            "Installing collected packages: pytorch-lightning\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 2.0.2\n",
            "    Uninstalling pytorch-lightning-2.0.2:\n",
            "      Successfully uninstalled pytorch-lightning-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "taming-transformers 0.0.1 requires pytorch-lightning>=1.0.8, but you have pytorch-lightning 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pytorch-lightning-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## importing libraries\n",
        "\n",
        "import numpy as np\n",
        "import torch, os, imageio, pdb, math\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "import PIL\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import yaml\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "gMuOZeGqQiOh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_from_tensor(tensor):\n",
        "  img = tensor.clone()\n",
        "  img = img.mul(255).byte()\n",
        "  img = img.cpu().numpy().transpose((1, 2, 0))\n",
        "\n",
        "  plt.figure(figsize=(10,7))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  plt.show()\n",
        "\n",
        "def norm_data(data):\n",
        "  return (data.clip(-1, 1)+1)/2  ### range between 0 and 1 "
      ],
      "metadata": {
        "id": "3wybdMD-ZAJs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### hyperparameters\n",
        "\n",
        "lr = .5\n",
        "batch_size = 1\n",
        "weight_decay = .1\n",
        "noise_factor = .1\n",
        "device = \"cuda\"\n",
        "\n",
        "total_iter = 100\n",
        "im_shape = [225, 400, 3] # height, width, channel\n",
        "size1, size2, channels = im_shape\n"
      ],
      "metadata": {
        "id": "cUSHswgTh7lL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### CLIP Model(connects texts with images) ==> Download\n",
        "\n",
        "!git clone https://github.com/openai/CLIP.git\n",
        "\n",
        "'''\n",
        "# CLIP module is not in python path. So, \n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/Colab Notebooks/CLIP')\n",
        "from CLIP import clip\n",
        "'''\n",
        "#!pip install CLIP\n",
        "# from CLIP import Clip  ==> wrong way of import\n",
        "from CLIP import clip # correct way"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5T6DdMAUwxsz",
        "outputId": "d787b0c7-3e31-4339-9fdd-8921c401be40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "remote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (243/243), 8.92 MiB | 22.06 MiB/s, done.\n",
            "Resolving deltas: 100% (124/124), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CLIP Model ==> Instantiation \n",
        "\n",
        "clipmodel, preprocess = clip.load(\"ViT-B/32\", device=device, jit=False)\n",
        "clipmodel.eval()\n",
        "print(clip.available_models())\n",
        "\n",
        "print(\"Clip model visual input resolution:\", clipmodel.visual.input_resolution)\n",
        "\n",
        "device = torch.device(\"cuda:0\")\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q47n8Yyeji2r",
        "outputId": "05873c44-712a-4507-8c5d-e8f94ff4fb1d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:05<00:00, 61.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'RN50x64', 'ViT-B/32', 'ViT-B/16', 'ViT-L/14', 'ViT-L/14@336px']\n",
            "Clip model visual input resolution: 224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Taming Transformer ==> Download \n",
        "\n",
        "!git clone https://github.com/CompVis/taming-transformers.git\n",
        "\n",
        "### VQGan Arch ==> Download\n",
        "\n",
        "%cd /content/taming-transformers/\n",
        "\n",
        "!mkdir -p models/vqgan_imagenet_f16_16384/chkpts\n",
        "!mkdir -p models/vqgan_imagenet_f16_16384/configs\n",
        "\n",
        "if len(os.listdir(\"models/vqgan_imagenet_f16_16384/chkpts/\")) == 0:\n",
        "  !wget \"https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1\" -O \"models/vqgan_imagenet_f16_16384/chkpts/last.ckpt\"  \n",
        "\n",
        "if len(os.listdir(\"models/vqgan_imagenet_f16_16384/configs/\")) == 0:\n",
        "  !wget \"https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1\" -O \"models/vqgan_imagenet_f16_16384/configs/model.yaml\"  \n",
        "\n",
        "!pip uninstall torchtext --yes # otherwise results in error during from taming.models.vqgan import VQModel\n",
        "!pip install --upgrade taming-transformers # otherwise results in torch._six import error"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S51noQEXl7YN",
        "outputId": "d5be756c-78a0-4564-ee8a-f94a9d0cfe68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'taming-transformers'...\n",
            "remote: Enumerating objects: 1339, done.\u001b[K\n",
            "remote: Total 1339 (delta 0), reused 0 (delta 0), pack-reused 1339\u001b[K\n",
            "Receiving objects: 100% (1339/1339), 409.77 MiB | 25.64 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n",
            "/content/taming-transformers\n",
            "--2023-05-02 10:15:06--  https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fckpts%2Flast.ckpt&dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/c8b3c54d-118e-43fc-a137-641e32802508/last.ckpt [following]\n",
            "--2023-05-02 10:15:09--  https://heibox.uni-heidelberg.de/seafhttp/files/c8b3c54d-118e-43fc-a137-641e32802508/last.ckpt\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 980092370 (935M) [application/octet-stream]\n",
            "Saving to: ‘models/vqgan_imagenet_f16_16384/chkpts/last.ckpt’\n",
            "\n",
            "models/vqgan_imagen 100%[===================>] 934.69M  12.9MB/s    in 63s     \n",
            "\n",
            "2023-05-02 10:16:12 (14.8 MB/s) - ‘models/vqgan_imagenet_f16_16384/chkpts/last.ckpt’ saved [980092370/980092370]\n",
            "\n",
            "--2023-05-02 10:16:12--  https://heibox.uni-heidelberg.de/d/a7530b09fed84f80a887/files/?p=%2Fconfigs%2Fmodel.yaml&dl=1\n",
            "Resolving heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)... 129.206.7.113\n",
            "Connecting to heibox.uni-heidelberg.de (heibox.uni-heidelberg.de)|129.206.7.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://heibox.uni-heidelberg.de/seafhttp/files/5f4bdc5b-1b2b-4fa8-bf83-727edd38446c/model.yaml [following]\n",
            "--2023-05-02 10:16:13--  https://heibox.uni-heidelberg.de/seafhttp/files/5f4bdc5b-1b2b-4fa8-bf83-727edd38446c/model.yaml\n",
            "Reusing existing connection to heibox.uni-heidelberg.de:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 692 [application/octet-stream]\n",
            "Saving to: ‘models/vqgan_imagenet_f16_16384/configs/model.yaml’\n",
            "\n",
            "models/vqgan_imagen 100%[===================>]     692  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-05-02 10:16:13 (48.9 KB/s) - ‘models/vqgan_imagenet_f16_16384/configs/model.yaml’ saved [692/692]\n",
            "\n",
            "Found existing installation: torchtext 0.15.1\n",
            "Uninstalling torchtext-0.15.1:\n",
            "  Successfully uninstalled torchtext-0.15.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting taming-transformers\n",
            "  Downloading taming_transformers-0.0.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (0.15.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (4.65.0)\n",
            "Requirement already satisfied: omegaconf>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from taming-transformers) (2.0.0)\n",
            "Collecting pytorch-lightning>=1.0.8 (from taming-transformers)\n",
            "  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0.0->taming-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0.0->taming-transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (2023.4.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning>=1.0.8->taming-transformers) (23.1)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->taming-transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->taming-transformers) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->taming-transformers) (16.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->taming-transformers) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->taming-transformers) (8.4.0)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->taming-transformers) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->taming-transformers) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->taming-transformers) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning>=1.0.8->taming-transformers)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning, taming-transformers\n",
            "  Attempting uninstall: pytorch-lightning\n",
            "    Found existing installation: pytorch-lightning 1.0.0\n",
            "    Uninstalling pytorch-lightning-1.0.0:\n",
            "      Successfully uninstalled pytorch-lightning-1.0.0\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.2 taming-transformers-0.0.1 torchmetrics-0.11.4 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### taming-transformer(VQGan) Model ==> Instantiation \n",
        "\n",
        "from taming.models.vqgan import VQModel\n",
        "\n",
        "def load_config(config_path, display=False):\n",
        "  config_data = OmegaConf.load(config_path)\n",
        "  if display:\n",
        "    print(yaml.dump(OmegaConf.to_container(config_data)))\n",
        "  return config_data\n",
        "\n",
        "def load_vqgan(config, chk_path=None):\n",
        "  model = VQModel(**config.model.params)\n",
        "  if chk_path is not None:\n",
        "    state_dict = torch.load(chk_path, map_location='cpu')[\"state_dict\"]\n",
        "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
        "  return model.eval()\n",
        "\n",
        "def generator(x):\n",
        "  x = taming_model.post_quant_conv(x)\n",
        "  x = taming_model.decoder(x)\n",
        "  return x\n",
        "\n",
        "taming_config = load_config(\"./models/vqgan_imagenet_f16_16384/configs/model.yaml\", display=True)\n",
        "taming_model = load_vqgan(taming_config, chk_path=\"./models/vqgan_imagenet_f16_16384/chkpts/last.ckpt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXwpP6sjo6Yj",
        "outputId": "56e954ab-121c-441b-d173-9da5f4ef2435"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:\n",
            "  base_learning_rate: 4.5e-06\n",
            "  params:\n",
            "    ddconfig:\n",
            "      attn_resolutions:\n",
            "      - 16\n",
            "      ch: 128\n",
            "      ch_mult:\n",
            "      - 1\n",
            "      - 1\n",
            "      - 2\n",
            "      - 2\n",
            "      - 4\n",
            "      double_z: false\n",
            "      dropout: 0.0\n",
            "      in_channels: 3\n",
            "      num_res_blocks: 2\n",
            "      out_ch: 3\n",
            "      resolution: 256\n",
            "      z_channels: 256\n",
            "    embed_dim: 256\n",
            "    lossconfig:\n",
            "      params:\n",
            "        codebook_weight: 1.0\n",
            "        disc_conditional: false\n",
            "        disc_in_channels: 3\n",
            "        disc_num_layers: 2\n",
            "        disc_start: 0\n",
            "        disc_weight: 0.75\n",
            "      target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator\n",
            "    monitor: val/rec_loss\n",
            "    n_embed: 16384\n",
            "  target: taming.models.vqgan.VQModel\n",
            "\n",
            "Working with z of shape (1, 256, 16, 16) = 65536 dimensions.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:12<00:00, 45.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading vgg_lpips model from https://heibox.uni-heidelberg.de/f/607503859c864bc1b30b/?dl=1 to taming/modules/autoencoder/lpips/vgg.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8.19kB [00:00, 140kB/s]                    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
            "VQLPIPSWithDiscriminator running with hinge loss.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### values that we are going to optimize to create beautiful images\n",
        "\n",
        "class Parameters(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Parameters, self).__init__()\n",
        "    self.data = .5*torch.randn(batch_size, 256, size1//16, size2//16).cuda() # 1 x 256 x 14 x 25\n",
        "    self.data = torch.nn.Parameter(torch.sin(self.data))\n",
        "\n",
        "  def forward(self):\n",
        "    return self.data\n",
        "\n",
        "def init_params():\n",
        "  params = Parameters().cuda()\n",
        "  optimizer = torch.optim.Adam([{'params':[params.data], 'lr':lr }], weight_decay = weight_decay)\n",
        "  return params, optimizer"
      ],
      "metadata": {
        "id": "dSHX_HQh8_bt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Encodings the text\n",
        "\n",
        "normalize = torchvision.transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "\n",
        "def encodeText(text):\n",
        "  t = clip.tokenize(text).cuda()\n",
        "  t = clipmodel.encode_text(t).detach().clone()\n",
        "  return t\n",
        "\n",
        "def createEncodings(include, exclude, extras):\n",
        "  include_enc = []\n",
        "  for text in include:\n",
        "    include_enc.append(encodeText(text))\n",
        "\n",
        "  exclude_enc = encodeText(exclude) if exclude != '' else 0\n",
        "  extras_enc = encodeText(extras) if exclude != '' else 0\n",
        "\n",
        "  return include_enc, exclude_enc, extras_enc\n"
      ],
      "metadata": {
        "id": "-3ZUN7eXDBHw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Image preprocess\n",
        "\n",
        "augTransform = torch.nn.Sequential(\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.RandomAffine(30, (.2, .2), fill=0)\n",
        ").cuda()"
      ],
      "metadata": {
        "id": "wjCRy1kqHjzj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Initiallize\n",
        "\n",
        "Params,  optimizer = init_params()\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(Params().shape)\n",
        "  img = norm_data(generator(Params()).cpu()) # 1 x 3 x 224 x 400 [225 x 400]\n",
        "  print(\"img dimensions:\", img.shape)\n",
        "  show_from_tensor(img[0])\n",
        "\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "78E3tOxWI_uI",
        "outputId": "f22d1bec-66a3-4f87-a8cd-e9224b460209"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-a1f3ee1e9f84>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Initiallize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mParams\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-22cc23014453>\u001b[0m in \u001b[0;36minit_params\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learning_rate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LwTTv63_NXh2"
      },
      "execution_count": 23,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}